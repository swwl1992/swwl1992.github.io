<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://wanwenli.com/atom.xml" rel="self" type="application/atom+xml" /><link href="https://wanwenli.com/" rel="alternate" type="text/html" /><updated>2020-10-31T11:51:12+08:00</updated><id>https://wanwenli.com/atom.xml</id><title type="html">Salmon Says</title><subtitle>Stay curious and keep asking questions</subtitle><author><name>Wan Wenli</name></author><entry><title type="html">My open-source contributions</title><link href="https://wanwenli.com/life/2020/10/21/open-source-contributions-by-2020.html" rel="alternate" type="text/html" title="My open-source contributions" /><published>2020-10-21T00:00:00+08:00</published><updated>2020-10-21T00:00:00+08:00</updated><id>https://wanwenli.com/life/2020/10/21/open-source-contributions-by-2020</id><content type="html" xml:base="https://wanwenli.com/life/2020/10/21/open-source-contributions-by-2020.html">&lt;h1 id=&quot;source-code&quot;&gt;Source code&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ohmyzsh/ohmyzsh/pull/9344&quot;&gt;ohmyzsh&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/aws/aws-node-termination-handler/pull/259&quot;&gt;aws-node-termination-handler&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/996icu/996.ICU/pull/25416&quot;&gt;996.ICU&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/petertodd/python-bitcoinlib/pull/177&quot;&gt;python-bitcoinlib&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;issues&quot;&gt;Issues&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes/ingress-nginx/issues/856#issuecomment-663989442&quot;&gt;ingress-nginx&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Wan Wenli</name></author><category term="open-source" /><category term="github" /><category term="technology" /><category term="programming" /><summary type="html">Source code ohmyzsh aws-node-termination-handler 996.ICU python-bitcoinlib Issues ingress-nginx</summary></entry><entry><title type="html">CKA exam tips</title><link href="https://wanwenli.com/kubernetes/2020/05/10/cka-exam-tips.html" rel="alternate" type="text/html" title="CKA exam tips" /><published>2020-05-10T00:00:00+08:00</published><updated>2020-05-10T00:00:00+08:00</updated><id>https://wanwenli.com/kubernetes/2020/05/10/cka-exam-tips</id><content type="html" xml:base="https://wanwenli.com/kubernetes/2020/05/10/cka-exam-tips.html">&lt;p&gt;It’s simple.
Just make sure that you have taken the course on Udemy and another practice.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/&quot;&gt;Certified Kubernetes Administrator (CKA) with Practice Tests&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://killer.sh/&quot;&gt;Killer Shell - Kubernetes Exam Simulator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please complete all practice tests in the Udemy course.&lt;/p&gt;

&lt;p&gt;I feel that the difficulty of those practices in Killer Shell is higher than that of the actual exam,
so do &lt;em&gt;not&lt;/em&gt; panic if you cannot finish them on time.
Another 2 good things about Killer Shell:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Its UI looks similar to the actual exam.&lt;/li&gt;
  &lt;li&gt;It gives you some really helpful tips on how to set up your exam environment,
e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vimrc&lt;/code&gt; configs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;glhf&lt;/p&gt;</content><author><name>Wan Wenli</name></author><category term="CKA" /><category term="k8s" /><summary type="html">It’s simple. Just make sure that you have taken the course on Udemy and another practice. Certified Kubernetes Administrator (CKA) with Practice Tests Killer Shell - Kubernetes Exam Simulator Please complete all practice tests in the Udemy course. I feel that the difficulty of those practices in Killer Shell is higher than that of the actual exam, so do not panic if you cannot finish them on time. Another 2 good things about Killer Shell: Its UI looks similar to the actual exam. It gives you some really helpful tips on how to set up your exam environment, e.g. vimrc configs. glhf</summary></entry><entry><title type="html">Delete a k8s namespace that is stuck in “Terminating” state</title><link href="https://wanwenli.com/kubernetes/2019/12/28/forcibly-delete-a-k8s-namespace.html" rel="alternate" type="text/html" title="Delete a k8s namespace that is stuck in &quot;Terminating&quot; state" /><published>2019-12-28T00:00:00+08:00</published><updated>2019-12-28T00:00:00+08:00</updated><id>https://wanwenli.com/kubernetes/2019/12/28/forcibly-delete-a-k8s-namespace</id><content type="html" xml:base="https://wanwenli.com/kubernetes/2019/12/28/forcibly-delete-a-k8s-namespace.html">&lt;p&gt;When you try to delete a namespace in k8s,
it might get stuck in Terminating state.
One of the most likely reasons is that
there are &lt;em&gt;finalizers&lt;/em&gt; that are unable to complete thus block the clean-up of a namespace.&lt;/p&gt;

&lt;p&gt;Helm cannot release anything to a terminating namespace.
Therefore a terminating namespace is effectively unusable.
The idea of the solution is to forcibly remove its finalizers.
The solution attached below is able to work even
when command &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubectl edit namespace&lt;/code&gt; does not.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;NAMESPACE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;force deleting namespace &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$NAMESPACE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
kubectl proxy &amp;amp;
kubectl get namespace &lt;span class=&quot;nv&quot;&gt;$NAMESPACE&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; json | jq &lt;span class=&quot;s1&quot;&gt;'.spec = {&quot;finalizers&quot;:[]}'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; temp.json
curl &lt;span class=&quot;nt&quot;&gt;-k&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt; PUT &lt;span class=&quot;nt&quot;&gt;--data-binary&lt;/span&gt; @temp.json 127.0.0.1:8001/api/v1/namespaces/&lt;span class=&quot;nv&quot;&gt;$NAMESPACE&lt;/span&gt;/finalize
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It uses &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubectl proxy&lt;/code&gt; to proxy the kube-api,
so that it is reachable from localhost.
Last but not the least, check whether all the cloud resources,
such as storage associated with PersistentVolumeClaim and load balancers,
are really terminated after executing the command.
The command fastens the termination of a namespace and some cloud resources might not be cleaned up very properly.&lt;/p&gt;</content><author><name>Wan Wenli</name></author><category term="k8s" /><summary type="html">When you try to delete a namespace in k8s, it might get stuck in Terminating state. One of the most likely reasons is that there are finalizers that are unable to complete thus block the clean-up of a namespace. Helm cannot release anything to a terminating namespace. Therefore a terminating namespace is effectively unusable. The idea of the solution is to forcibly remove its finalizers. The solution attached below is able to work even when command kubectl edit namespace does not. NAMESPACE=$1 echo &quot;force deleting namespace $NAMESPACE&quot; kubectl proxy &amp;amp; kubectl get namespace $NAMESPACE -o json | jq '.spec = {&quot;finalizers&quot;:[]}' &amp;gt; temp.json curl -k -H &quot;Content-Type: application/json&quot; -X PUT --data-binary @temp.json 127.0.0.1:8001/api/v1/namespaces/$NAMESPACE/finalize It uses kubectl proxy to proxy the kube-api, so that it is reachable from localhost. Last but not the least, check whether all the cloud resources, such as storage associated with PersistentVolumeClaim and load balancers, are really terminated after executing the command. The command fastens the termination of a namespace and some cloud resources might not be cleaned up very properly.</summary></entry><entry><title type="html">A pod IP is released after the pod is deleted</title><link href="https://wanwenli.com/kubernetes/2019/10/15/calico-cni-release-pod-ip.html" rel="alternate" type="text/html" title="A pod IP is released after the pod is deleted" /><published>2019-10-15T00:00:00+08:00</published><updated>2019-10-15T00:00:00+08:00</updated><id>https://wanwenli.com/kubernetes/2019/10/15/calico-cni-release-pod-ip</id><content type="html" xml:base="https://wanwenli.com/kubernetes/2019/10/15/calico-cni-release-pod-ip.html">&lt;h1 id=&quot;prerequisite&quot;&gt;Prerequisite&lt;/h1&gt;

&lt;p&gt;Calico CNI is installed in your k8s cluster.&lt;/p&gt;

&lt;h1 id=&quot;ip-assigned-by-k8s&quot;&gt;IP assigned by k8s&lt;/h1&gt;

&lt;p&gt;In the experiment I have performed,
the pod IP is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;100.112.209.159&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;go-into-an-etcd-pod&quot;&gt;Go into an etcd pod&lt;/h1&gt;

&lt;p&gt;Try &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubectl exec&lt;/code&gt; into an etcd pod.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl exec -it -n kube-system &amp;lt;etcd_pod_name&amp;gt; sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;list-all-cidr-blocks&quot;&gt;List all CIDR blocks&lt;/h1&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;etcdctl ls /calico/ipam/v2/assignment/ipv4/block/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Find out that the aforementioned IP falls under CIDR 100.112.209.128/26&lt;/p&gt;

&lt;h1 id=&quot;get-the-block-infometadata&quot;&gt;Get the block info/metadata&lt;/h1&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;etcdctl get /calico/ipam/v2/assignment/ipv4/block/100.112.209.128-26
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;test-it-by-go&quot;&gt;Test it by Go&lt;/h1&gt;

&lt;p&gt;The code below is inspired by https://github.com/projectcalico/libcalico-go/blob/master/lib/backend/model/block.go&lt;/p&gt;

&lt;p&gt;Copy the JSON you have pasted from the section above,
and paste into the first line of function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TestCalicoBlock&lt;/code&gt; below.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TestCalicoBlock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;testing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;bytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;byte&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;`{&quot;cidr&quot;:&quot;100.112.209.128/26&quot;,&quot;affinity&quot;:&quot;host:ip-10-200-205-203&quot;,&quot;strictAffinity&quot;:false,&quot;allocations&quot;:[0,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,3,null,null,null,null,null,7,null,null,null,null,null,null,null,null,null,null,5,null,null,null,null,null,null,null,2,null,null,null,null,8,null,null,null,null,null,null,null,null,4,null,null,null,null,null,null,6,null],&quot;unallocated&quot;:[45,32,47,12,3,48,40,14,31,60,26,10,29,18,30,17,63,5,57,11,39,36,34,1,15,56,7,42,37,9,53,44,21,38,58,49,35,23,54,59,25,51,24,28,61,50,13,19,4,27,43,52,8,20,6],&quot;attributes&quot;:[{&quot;handle_id&quot;:null,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.884e11ced699fe17a493ffd59f18c97fd090fd8150411a11643a280a8250c510&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.3abca72fb5d92129ce16d631fcff2a024b422a48389107600d3ab02e997b484a&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.ba885aa5bb2e7f4124867d23f8975c5c3f42bd9d29632d535d90ebe516341c66&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.2c02fa9db03c347bc005c225331bea5422c86fd70b4c194462dbb56ffe8b253a&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.2caf1c8381761431c694771227eec339c5c0bb0ed3f11a6f2067883d5f405b69&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.84a415903469eb4d965002b7ad8d377e36c93746e0a53944d915695903f7d416&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.820a2747f282dc6cce92d5d544ea8e778a7fa787e219cc1c9757a58aa7a08455&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.1ba612190e9a571ea1253e52834cba4d746ffd75b303ec0706c4ffe8845fe655&quot;,&quot;secondary&quot;:null}]}`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;allocations&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AllocationBlock&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Unmarshal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allocations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrIdx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;allocations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Allocations&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrIdx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;nil&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;fmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OrdinalToIP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allocations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IP&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrdinalToIP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ord&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AllocationBlock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IP&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NewInt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IPToBigInt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CIDR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NewInt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BigIntToIP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IPToBigInt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;To4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;nil&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NewInt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SetBytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;To4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NewInt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SetBytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;To16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BigIntToIP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ipInt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IP&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ipInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())}&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h1 id=&quot;output&quot;&gt;Output&lt;/h1&gt;

&lt;p&gt;Before running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubectl delete&lt;/code&gt; command to delete the pod,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;100.112.209.159&lt;/code&gt; was in the list.&lt;/p&gt;

&lt;p&gt;However, &lt;em&gt;after&lt;/em&gt; the pod has been removed,
the output becomes as follows.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;100.112.209.128
100.112.209.130
100.112.209.144
100.112.209.150
100.112.209.161
100.112.209.169
100.112.209.174
100.112.209.183
100.112.209.190
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;100.112.209.159&lt;/code&gt; is gone, because it has been released.&lt;/p&gt;</content><author><name>Wan Wenli</name></author><category term="k8s" /><category term="calico" /><category term="CNI" /><category term="networking" /><summary type="html">Prerequisite Calico CNI is installed in your k8s cluster. IP assigned by k8s In the experiment I have performed, the pod IP is 100.112.209.159. Go into an etcd pod Try kubectl exec into an etcd pod. kubectl exec -it -n kube-system &amp;lt;etcd_pod_name&amp;gt; sh List all CIDR blocks etcdctl ls /calico/ipam/v2/assignment/ipv4/block/ Find out that the aforementioned IP falls under CIDR 100.112.209.128/26 Get the block info/metadata etcdctl get /calico/ipam/v2/assignment/ipv4/block/100.112.209.128-26 Test it by Go The code below is inspired by https://github.com/projectcalico/libcalico-go/blob/master/lib/backend/model/block.go Copy the JSON you have pasted from the section above, and paste into the first line of function TestCalicoBlock below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 func TestCalicoBlock(t *testing.T) { bytes := []byte(`{&quot;cidr&quot;:&quot;100.112.209.128/26&quot;,&quot;affinity&quot;:&quot;host:ip-10-200-205-203&quot;,&quot;strictAffinity&quot;:false,&quot;allocations&quot;:[0,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,3,null,null,null,null,null,7,null,null,null,null,null,null,null,null,null,null,5,null,null,null,null,null,null,null,2,null,null,null,null,8,null,null,null,null,null,null,null,null,4,null,null,null,null,null,null,6,null],&quot;unallocated&quot;:[45,32,47,12,3,48,40,14,31,60,26,10,29,18,30,17,63,5,57,11,39,36,34,1,15,56,7,42,37,9,53,44,21,38,58,49,35,23,54,59,25,51,24,28,61,50,13,19,4,27,43,52,8,20,6],&quot;attributes&quot;:[{&quot;handle_id&quot;:null,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.884e11ced699fe17a493ffd59f18c97fd090fd8150411a11643a280a8250c510&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.3abca72fb5d92129ce16d631fcff2a024b422a48389107600d3ab02e997b484a&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.ba885aa5bb2e7f4124867d23f8975c5c3f42bd9d29632d535d90ebe516341c66&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.2c02fa9db03c347bc005c225331bea5422c86fd70b4c194462dbb56ffe8b253a&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.2caf1c8381761431c694771227eec339c5c0bb0ed3f11a6f2067883d5f405b69&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.84a415903469eb4d965002b7ad8d377e36c93746e0a53944d915695903f7d416&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.820a2747f282dc6cce92d5d544ea8e778a7fa787e219cc1c9757a58aa7a08455&quot;,&quot;secondary&quot;:null},{&quot;handle_id&quot;:&quot;k8s-pod-network.1ba612190e9a571ea1253e52834cba4d746ffd75b303ec0706c4ffe8845fe655&quot;,&quot;secondary&quot;:null}]}`) var allocations model.AllocationBlock _ = json.Unmarshal(bytes, &amp;amp;allocations) for ord, attrIdx := range allocations.Allocations { if attrIdx == nil { continue } fmt.Println(OrdinalToIP(ord, &amp;amp;allocations)) } } type IP struct { net.IP } func OrdinalToIP(ord int, b *model.AllocationBlock) IP { sum := big.NewInt(0).Add(IPToBigInt(IP{IP: b.CIDR.IP}), big.NewInt(int64(ord))) return BigIntToIP(sum) } func IPToBigInt(ip IP) *big.Int { if ip.To4() != nil { return big.NewInt(0).SetBytes(ip.To4()) } else { return big.NewInt(0).SetBytes(ip.To16()) } } func BigIntToIP(ipInt *big.Int) IP { ip := IP{net.IP(ipInt.Bytes())} return ip } Output Before running kubectl delete command to delete the pod, 100.112.209.159 was in the list. However, after the pod has been removed, the output becomes as follows. 100.112.209.128 100.112.209.130 100.112.209.144 100.112.209.150 100.112.209.161 100.112.209.169 100.112.209.174 100.112.209.183 100.112.209.190 Conclusion 100.112.209.159 is gone, because it has been released.</summary></entry><entry><title type="html">Why a cluster role binding is needed in k8s-vault integration</title><link href="https://wanwenli.com/kubernetes/2019/08/28/k8s-tokenreview-api-vault.html" rel="alternate" type="text/html" title="Why a cluster role binding is needed in k8s-vault integration" /><published>2019-08-28T00:00:00+08:00</published><updated>2019-08-28T00:00:00+08:00</updated><id>https://wanwenli.com/kubernetes/2019/08/28/k8s-tokenreview-api-vault</id><content type="html" xml:base="https://wanwenli.com/kubernetes/2019/08/28/k8s-tokenreview-api-vault.html">&lt;h1 id=&quot;tl-dr&quot;&gt;TL; DR&lt;/h1&gt;
&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;system:auth-delegator&lt;/code&gt; ClusterRole allows a client to use a service account token to query the
&lt;a href=&quot;https://docs.openshift.com/container-platform/4.4/rest_api/authorization_apis/tokenreview-authentication-k8s-io-v1.html&quot;&gt;TokenReview API&lt;/a&gt;.
If a token is not bound to this ClusterRole,
the token cannot be reviewed by the k8s.&lt;/p&gt;

&lt;h1 id=&quot;background&quot;&gt;Background&lt;/h1&gt;

&lt;p&gt;In the
&lt;a href=&quot;https://www.vaultproject.io/docs/auth/kubernetes.html&quot;&gt;official Kubernetes Auth Method&lt;/a&gt;
of
&lt;a href=&quot;https://www.vaultproject.io/&quot;&gt;Vault&lt;/a&gt;
and other online sources,
it is found that a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterRoleBinding&lt;/code&gt; is always there.
You may wonder why a service account needs such a cluster-level permission
in order to authenticate with Vault.
This article attempts to dive into k8s API to explain the mechanism.&lt;/p&gt;

&lt;p&gt;More can be found in
&lt;a href=&quot;https://kubernetes.io/docs/reference/access-authn-authz/authentication/#webhook-token-authentication&quot;&gt;this link&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;what-is-clusterrole-systemauth-delegator-all-about&quot;&gt;What is ClusterRole system:auth-delegator all about&lt;/h1&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get clusterrole system:auth-delegator -o yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From the output yaml you will be able to see that it allows creating token reviews with k8s API.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ClusterRole&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;rbac.authorization.kubernetes.io/autoupdate&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;true&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;creationTimestamp&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2018-01-01T00:00:00Z&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;kubernetes.io/bootstrapping&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac-defaults&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;system:auth-delegator&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resourceVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;99&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;selfLink&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aauth-delegator&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;uid&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;da0c44d5-1111-1111-1111-063ccccda29e&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;authentication.k8s.io&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;tokenreviews&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;create&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;authorization.k8s.io&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;subjectaccessreviews&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;create&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;play-with-tokenreview-api&quot;&gt;Play with TokenReview API&lt;/h1&gt;

&lt;p&gt;Simply put,
this API tells whether a token is from a legit user of the cluster.&lt;/p&gt;

&lt;p&gt;Switch to a k8s&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl config use-context &amp;lt;target_k8s_cluster&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Get the service account token of an application. Alternatively, get the service account secret and parse the JSON.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl exec -it &amp;lt;pod_name&amp;gt; cat /var/run/secrets/kubernetes.io/serviceaccount/token
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Copy the token and go into a tmp directory.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /tmp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Write a file with the following content,
fill in the token and
name the file as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;token-review.json&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;apiVersion&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;authentication.k8s.io/v1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;kind&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;TokenReview&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;spec&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&amp;lt;YOUR_SERVICE_ACCOUNT_TOKEN&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Save the file and run the commands below.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;TOKEN&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&amp;lt;YOUR_SERVICE_ACCOUNT_TOKEN&amp;gt;&quot;&lt;/span&gt;
curl &lt;span class=&quot;nt&quot;&gt;-k&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt; POST &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; @token-review.json &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: Bearer &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TOKEN&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Accept: application/json'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Content-Type: application/json'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 https://&amp;lt;kubernetes_api_host_and_port&amp;gt;/apis/authentication.k8s.io/v1/tokenreviews
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;

&lt;p&gt;If the service account has a ClusterRoleBinding with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;system:auth-delegator&lt;/code&gt;,
the API would return code 200,
with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;system:serviceaccount:&amp;lt;service_account_namespace&amp;gt;:&amp;lt;service_account_name&amp;gt;&lt;/code&gt;
in the user field of the response JSON as below.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;kind&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;TokenReview&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;apiVersion&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;authentication.k8s.io/v1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;metadata&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;creationTimestamp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;spec&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&amp;lt;YOUR_SERVICE_ACCOUNT_TOKEN&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;authenticated&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;user&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;username&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;system:serviceaccount:&amp;lt;service_account_namespace&amp;gt;:&amp;lt;service_account_name&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;uid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;3a366063-9999-9999-9999-0659048d2f3e&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;groups&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;system:serviceaccounts&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;system:authenticated&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From it we also know that when we configure the Vault role for authenticating a k8s service account,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;service_account_name&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;service_account_namespace&lt;/code&gt; must be configured correctly.
Because the response from k8s API includes the service account name and its namespace.&lt;/p&gt;

&lt;p&gt;If there is no such a binding, the response code would be 403 and the response JSON as below.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;kind&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Status&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;apiVersion&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;v1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;metadata&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Failure&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;message&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;tokenreviews.authentication.k8s.io is forbidden: User &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;system:serviceaccount:&amp;lt;service_account_namespace&amp;gt;:&amp;lt;service_account_name&amp;gt;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; cannot create tokenreviews.authentication.k8s.io at the cluster scope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;reason&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Forbidden&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;details&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;authentication.k8s.io&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;kind&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;tokenreviews&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;code&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;403&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Wan Wenli</name></author><category term="k8s" /><category term="vault" /><summary type="html">TL; DR The system:auth-delegator ClusterRole allows a client to use a service account token to query the TokenReview API. If a token is not bound to this ClusterRole, the token cannot be reviewed by the k8s. Background In the official Kubernetes Auth Method of Vault and other online sources, it is found that a ClusterRoleBinding is always there. You may wonder why a service account needs such a cluster-level permission in order to authenticate with Vault. This article attempts to dive into k8s API to explain the mechanism. More can be found in this link. What is ClusterRole system:auth-delegator all about kubectl get clusterrole system:auth-delegator -o yaml From the output yaml you will be able to see that it allows creating token reviews with k8s API. apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot; creationTimestamp: &quot;2018-01-01T00:00:00Z&quot; labels: kubernetes.io/bootstrapping: rbac-defaults name: system:auth-delegator resourceVersion: &quot;99&quot; selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aauth-delegator uid: da0c44d5-1111-1111-1111-063ccccda29e rules: - apiGroups: - authentication.k8s.io resources: - tokenreviews verbs: - create - apiGroups: - authorization.k8s.io resources: - subjectaccessreviews verbs: - create Play with TokenReview API Simply put, this API tells whether a token is from a legit user of the cluster. Switch to a k8s kubectl config use-context &amp;lt;target_k8s_cluster&amp;gt; Get the service account token of an application. Alternatively, get the service account secret and parse the JSON. kubectl exec -it &amp;lt;pod_name&amp;gt; cat /var/run/secrets/kubernetes.io/serviceaccount/token Copy the token and go into a tmp directory. cd /tmp Write a file with the following content, fill in the token and name the file as token-review.json. { &quot;apiVersion&quot;: &quot;authentication.k8s.io/v1&quot;, &quot;kind&quot;: &quot;TokenReview&quot;, &quot;spec&quot;: { &quot;token&quot;: &quot;&amp;lt;YOUR_SERVICE_ACCOUNT_TOKEN&amp;gt;&quot; } } Save the file and run the commands below. export TOKEN=&quot;&amp;lt;YOUR_SERVICE_ACCOUNT_TOKEN&amp;gt;&quot; curl -k -v \ -X POST \ -d @token-review.json \ -H &quot;Authorization: Bearer $TOKEN&quot; \ -H 'Accept: application/json' \ -H 'Content-Type: application/json' \ https://&amp;lt;kubernetes_api_host_and_port&amp;gt;/apis/authentication.k8s.io/v1/tokenreviews Discussion If the service account has a ClusterRoleBinding with system:auth-delegator, the API would return code 200, with system:serviceaccount:&amp;lt;service_account_namespace&amp;gt;:&amp;lt;service_account_name&amp;gt; in the user field of the response JSON as below. { &quot;kind&quot;: &quot;TokenReview&quot;, &quot;apiVersion&quot;: &quot;authentication.k8s.io/v1&quot;, &quot;metadata&quot;: { &quot;creationTimestamp&quot;: null }, &quot;spec&quot;: { &quot;token&quot;: &quot;&amp;lt;YOUR_SERVICE_ACCOUNT_TOKEN&amp;gt;&quot; }, &quot;status&quot;: { &quot;authenticated&quot;: true, &quot;user&quot;: { &quot;username&quot;: &quot;system:serviceaccount:&amp;lt;service_account_namespace&amp;gt;:&amp;lt;service_account_name&amp;gt;&quot;, &quot;uid&quot;: &quot;3a366063-9999-9999-9999-0659048d2f3e&quot;, &quot;groups&quot;: [ &quot;system:serviceaccounts&quot;, &quot;system:authenticated&quot; ] } } } From it we also know that when we configure the Vault role for authenticating a k8s service account, service_account_name and service_account_namespace must be configured correctly. Because the response from k8s API includes the service account name and its namespace. If there is no such a binding, the response code would be 403 and the response JSON as below. { &quot;kind&quot;: &quot;Status&quot;, &quot;apiVersion&quot;: &quot;v1&quot;, &quot;metadata&quot;: { }, &quot;status&quot;: &quot;Failure&quot;, &quot;message&quot;: &quot;tokenreviews.authentication.k8s.io is forbidden: User \&quot;system:serviceaccount:&amp;lt;service_account_namespace&amp;gt;:&amp;lt;service_account_name&amp;gt;\&quot; cannot create tokenreviews.authentication.k8s.io at the cluster scope&quot;, &quot;reason&quot;: &quot;Forbidden&quot;, &quot;details&quot;: { &quot;group&quot;: &quot;authentication.k8s.io&quot;, &quot;kind&quot;: &quot;tokenreviews&quot; }, &quot;code&quot;: 403 }</summary></entry><entry><title type="html">Too many redirects when forcing SSL redirection on an ingress</title><link href="https://wanwenli.com/kubernetes/2019/05/29/k8s-ingress-force-ssl-redirect.html" rel="alternate" type="text/html" title="Too many redirects when forcing SSL redirection on an ingress" /><published>2019-05-29T00:00:00+08:00</published><updated>2019-05-29T00:00:00+08:00</updated><id>https://wanwenli.com/kubernetes/2019/05/29/k8s-ingress-force-ssl-redirect</id><content type="html" xml:base="https://wanwenli.com/kubernetes/2019/05/29/k8s-ingress-force-ssl-redirect.html">&lt;p&gt;In summary, these are the steps for SSL redirection to work properly and
this method has been mentioned by
&lt;a href=&quot;https://stackoverflow.com/a/64224737/1397473&quot;&gt;this answer on stackoverflow&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;use-forwarded-headers: &quot;true&quot;&lt;/code&gt; into the ConfigMap of ingress controller&lt;/li&gt;
  &lt;li&gt;Do a rolling upgrade on the deployment of Nginx ingress controller,
so that the new value in the ConfigMap would be picked up.&lt;/li&gt;
  &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nginx.ingress.kubernetes.io/force-ssl-redirect: &quot;true&quot;&lt;/code&gt; into the annotations of an ingress&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I found this by reading the source code of
&lt;a href=&quot;https://github.com/kubernetes/ingress-nginx&quot;&gt;ingress-nginx&lt;/a&gt;.
Here is a detailed explanation on how it works.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TOO_MANY_REDIRECTS&lt;/code&gt; error happens because no matter HTTP or HTTPS is used,
Nginx controller always return
&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/308&quot;&gt;308 REDIRECT&lt;/a&gt;
to clients.
Next, the browser goes into an infinite loop of redirections.
Why? In the following section it will be explained.&lt;/p&gt;

&lt;p&gt;When &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;force-ssl-redirect&lt;/code&gt; annotation is set to true on an ingress level,
Nginx ingress controller adds/updates the following snippet into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nginx.conf&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;n&quot;&gt;rewrite_by_lua_block&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lua_ingress&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rewrite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;force_ssl_redirect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;use_port_in_redirects&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;balancer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rewrite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Note: when SSL redirect is false in an ingress, the value of force_ssl_redirect is also false.&lt;/p&gt;

&lt;p&gt;These are the a few code snippets you will need to look into to understand how this fix works.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In the source code of ingress-nginx,
&lt;a href=&quot;https://github.com/kubernetes/ingress-nginx/blob/bf11e2ef636cd535b66ebb2ab638a941662da699/rootfs/etc/nginx/lua/lua_ingress.lua#L122&quot;&gt;here&lt;/a&gt;
defines how the Lua block in nginx.conf works.&lt;/li&gt;
  &lt;li&gt;When force_ssl_redirect is true, function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redirect_to_https&lt;/code&gt; alone determines whether the request should be redirected.&lt;/li&gt;
  &lt;li&gt;According to the implementation of
&lt;a href=&quot;https://github.com/kubernetes/ingress-nginx/blob/bf11e2ef636cd535b66ebb2ab638a941662da699/rootfs/etc/nginx/lua/lua_ingress.lua#L57&quot;&gt;redirect_to_https&lt;/a&gt;,
its return value solely depends on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ngx.var.pass_access_scheme&lt;/code&gt;,
because &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ngx.var.scheme&lt;/code&gt; is either http or https. Later I will argue that it has always been http.&lt;/li&gt;
  &lt;li&gt;According
&lt;a href=&quot;https://github.com/kubernetes/ingress-nginx/blob/bf11e2ef636cd535b66ebb2ab638a941662da699/rootfs/etc/nginx/lua/lua_ingress.lua#L97&quot;&gt;this chunk&lt;/a&gt;,
it takes the value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http_x_forwarded_proto&lt;/code&gt; if &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;use-forwarded-headers&lt;/code&gt; is true and
that’s why it is enabled in ingress controller.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since the following snippet works as a hacky way,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http_x_forwarded_proto&lt;/code&gt; must reflect the true protocol of the request.&lt;/p&gt;

&lt;div class=&quot;language-nginx highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$http_x_forwarded_proto&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'https')&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;301&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$host$request_uri&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Q.E.D.&lt;/p&gt;</content><author><name>Wan Wenli</name></author><category term="kubernetes" /><category term="k8s" /><category term="nginx-ingress-controller" /><summary type="html">In summary, these are the steps for SSL redirection to work properly and this method has been mentioned by this answer on stackoverflow. Add use-forwarded-headers: &quot;true&quot; into the ConfigMap of ingress controller Do a rolling upgrade on the deployment of Nginx ingress controller, so that the new value in the ConfigMap would be picked up. Add nginx.ingress.kubernetes.io/force-ssl-redirect: &quot;true&quot; into the annotations of an ingress I found this by reading the source code of ingress-nginx. Here is a detailed explanation on how it works. The TOO_MANY_REDIRECTS error happens because no matter HTTP or HTTPS is used, Nginx controller always return 308 REDIRECT to clients. Next, the browser goes into an infinite loop of redirections. Why? In the following section it will be explained. When force-ssl-redirect annotation is set to true on an ingress level, Nginx ingress controller adds/updates the following snippet into nginx.conf. rewrite_by_lua_block { lua_ingress.rewrite({ force_ssl_redirect = true, use_port_in_redirects = false, }) balancer.rewrite() plugins.run() } Note: when SSL redirect is false in an ingress, the value of force_ssl_redirect is also false. These are the a few code snippets you will need to look into to understand how this fix works. In the source code of ingress-nginx, here defines how the Lua block in nginx.conf works. When force_ssl_redirect is true, function redirect_to_https alone determines whether the request should be redirected. According to the implementation of redirect_to_https, its return value solely depends on ngx.var.pass_access_scheme, because ngx.var.scheme is either http or https. Later I will argue that it has always been http. According this chunk, it takes the value of http_x_forwarded_proto if use-forwarded-headers is true and that’s why it is enabled in ingress controller. Since the following snippet works as a hacky way, http_x_forwarded_proto must reflect the true protocol of the request. if ($http_x_forwarded_proto != 'https') { return 301 https://$host$request_uri; } Q.E.D.</summary></entry><entry><title type="html">How do Bitcoin mining pools pay their miners?</title><link href="https://wanwenli.com/blockchain/2018/09/13/How-do-bitcoin-mining-pools-pay.html" rel="alternate" type="text/html" title="How do Bitcoin mining pools pay their miners?" /><published>2018-09-13T00:00:00+08:00</published><updated>2018-09-13T00:00:00+08:00</updated><id>https://wanwenli.com/blockchain/2018/09/13/How-do-bitcoin-mining-pools-pay</id><content type="html" xml:base="https://wanwenli.com/blockchain/2018/09/13/How-do-bitcoin-mining-pools-pay.html">&lt;p&gt;Since the price of Bitcoin surged in the 2017 Q4,
many mining pools have surfaced.
Over the globe there are over 20 active and recognizable mining pools.
You can find more pools and their addresses from
&lt;a href=&quot;https://github.com/btccom/Blockchain-Known-Pools/blob/master/pools.json&quot;&gt;this GitHub repo&lt;/a&gt;.
This article explains a particular type of routine job in a Bitcoin mining pool:
how does it pay Bitcoins to its miners?
Actually you will find out that it might not be the same as you thought.&lt;/p&gt;

&lt;h3 id=&quot;directly-from-coinbase-addresses&quot;&gt;Directly from coinbase addresses&lt;/h3&gt;

&lt;p&gt;This is the simplest way.
SlushPool has been using this method for some time.
You can easily find payout transactions miners from address
&lt;a href=&quot;https://btc.com/1CK6KHY6MHgYvmRQ4PAafKYDrg1ejbH1cE&quot;&gt;1CK6KHY6MHgYvmRQ4PAafKYDrg1ejbH1cE&lt;/a&gt;
which is the publicly known coinbase address of SlushPool.
On a typical day you can observe more than five transactions from this address
each of which is with a huge number of outputs to various addresses -
it is the typical way of identifying payments from a mining pool to its miners.&lt;/p&gt;

&lt;p&gt;Other pools that also use this method are
BTC.TOP and Huobi Pool.
However, you can find that BTC.TOP also uses intermediate addresses to pay its miners.&lt;/p&gt;

&lt;h3 id=&quot;pay-via-intermediate-wallets&quot;&gt;Pay via intermediate wallets&lt;/h3&gt;

&lt;p&gt;This is probably the most common practice of pools.
Take &lt;a href=&quot;https://btc.com&quot;&gt;BTC.com&lt;/a&gt; for example,
you can find its coinbase address is
&lt;a href=&quot;https://btc.com/bc1qjl8uwezzlech723lpnyuza0h2cdkvxvh54v3dn&quot;&gt;bc1qjl8uwezzlech723lpnyuza0h2cdkvxvh54v3dn&lt;/a&gt;.
There are many transactions associated with this address,
most of which are coinbase transactions.
However there are some Bitcoins sent by it to other addresses,
for example,
&lt;a href=&quot;https://btc.com/3FxUA8godrRmxgUaPv71b3XCUxcoCLtUx2&quot;&gt;3FxUA8godrRmxgUaPv71b3XCUxcoCLtUx2&lt;/a&gt;
in transaction
&lt;a href=&quot;https://btc.com/d094eca893253c12bb53f55ed834281349eda9e59505fa91d07e114fd616aa02&quot;&gt;d094eca893253c12bb53f55ed834281349eda9e59505fa91d07e114fd616aa02&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Therefore,
&lt;a href=&quot;https://btc.com/3FxUA8godrRmxgUaPv71b3XCUxcoCLtUx2&quot;&gt;3FxUA8godrRmxgUaPv71b3XCUxcoCLtUx2&lt;/a&gt;
is one of the intermediate addresses used by BTC.com.
Every day there are a few transactions from it to many addresses,
probably thousands of outputs in a single transaction,
and this is how BTC.com pays its miners.&lt;/p&gt;

&lt;h3 id=&quot;antpool-payments-chain&quot;&gt;AntPool: payments chain&lt;/h3&gt;

&lt;p&gt;AntPool is a very special case and
its payment pattern is the most difficult to trace.
The whole process of payments is like a chain or loop.
Almost every day it starts from in the morning
and last until late afternoon.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Generate a new wallet&lt;/li&gt;
  &lt;li&gt;Use the intermediate address to pay 101 addresses&lt;/li&gt;
  &lt;li&gt;Among the 101 recipients 100 are miners,
while the one newly generated wallet receives &lt;em&gt;all&lt;/em&gt; the change&lt;/li&gt;
  &lt;li&gt;Use the balance in the change wallet to pay another 100 miners + 1 new wallet&lt;/li&gt;
  &lt;li&gt;Repeat the process above until all miner addresses are paid&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The end result is that all the intermediate change wallets are empty and
they will &lt;em&gt;not&lt;/em&gt; be reused.
Only the very last change wallet has some Bitcoins in it.
Personally I like this process because it gives the miners highest level of
privacy.
If you wish to find out all miners’ addresses under AntPool by hands,
you have to traverse many transactions.
But for other pools, you only need to checkout less than ten transactions,
probably even less than five.&lt;/p&gt;

&lt;h3 id=&quot;f2pool-pay-without-transaction-fees&quot;&gt;F2Pool: pay without transaction fees&lt;/h3&gt;

&lt;p&gt;Everyday F2Pool broadcasts a transaction with zero transaction fee
to pay its miners.
After that, F2Pool tries to mine it because
no other miner is willing to mine a transaction without any fee.
This approach saves money, apparently.
A major disadvantage of it is there are huge
uncertainties in the time when its miners receive Bitcoins.&lt;/p&gt;</content><author><name>Wan Wenli</name></author><category term="blockchain" /><category term="bitcoin" /><summary type="html">Since the price of Bitcoin surged in the 2017 Q4, many mining pools have surfaced. Over the globe there are over 20 active and recognizable mining pools. You can find more pools and their addresses from this GitHub repo. This article explains a particular type of routine job in a Bitcoin mining pool: how does it pay Bitcoins to its miners? Actually you will find out that it might not be the same as you thought. Directly from coinbase addresses This is the simplest way. SlushPool has been using this method for some time. You can easily find payout transactions miners from address 1CK6KHY6MHgYvmRQ4PAafKYDrg1ejbH1cE which is the publicly known coinbase address of SlushPool. On a typical day you can observe more than five transactions from this address each of which is with a huge number of outputs to various addresses - it is the typical way of identifying payments from a mining pool to its miners. Other pools that also use this method are BTC.TOP and Huobi Pool. However, you can find that BTC.TOP also uses intermediate addresses to pay its miners. Pay via intermediate wallets This is probably the most common practice of pools. Take BTC.com for example, you can find its coinbase address is bc1qjl8uwezzlech723lpnyuza0h2cdkvxvh54v3dn. There are many transactions associated with this address, most of which are coinbase transactions. However there are some Bitcoins sent by it to other addresses, for example, 3FxUA8godrRmxgUaPv71b3XCUxcoCLtUx2 in transaction d094eca893253c12bb53f55ed834281349eda9e59505fa91d07e114fd616aa02. Therefore, 3FxUA8godrRmxgUaPv71b3XCUxcoCLtUx2 is one of the intermediate addresses used by BTC.com. Every day there are a few transactions from it to many addresses, probably thousands of outputs in a single transaction, and this is how BTC.com pays its miners. AntPool: payments chain AntPool is a very special case and its payment pattern is the most difficult to trace. The whole process of payments is like a chain or loop. Almost every day it starts from in the morning and last until late afternoon. Generate a new wallet Use the intermediate address to pay 101 addresses Among the 101 recipients 100 are miners, while the one newly generated wallet receives all the change Use the balance in the change wallet to pay another 100 miners + 1 new wallet Repeat the process above until all miner addresses are paid The end result is that all the intermediate change wallets are empty and they will not be reused. Only the very last change wallet has some Bitcoins in it. Personally I like this process because it gives the miners highest level of privacy. If you wish to find out all miners’ addresses under AntPool by hands, you have to traverse many transactions. But for other pools, you only need to checkout less than ten transactions, probably even less than five. F2Pool: pay without transaction fees Everyday F2Pool broadcasts a transaction with zero transaction fee to pay its miners. After that, F2Pool tries to mine it because no other miner is willing to mine a transaction without any fee. This approach saves money, apparently. A major disadvantage of it is there are huge uncertainties in the time when its miners receive Bitcoins.</summary></entry><entry><title type="html">A brief guide to Bitcoin lightning network with examples</title><link href="https://wanwenli.com/blockchain/2018/06/28/Bitcoin-lightning-network.html" rel="alternate" type="text/html" title="A brief guide to Bitcoin lightning network with examples" /><published>2018-06-28T00:00:00+08:00</published><updated>2018-06-28T00:00:00+08:00</updated><id>https://wanwenli.com/blockchain/2018/06/28/Bitcoin-lightning-network</id><content type="html" xml:base="https://wanwenli.com/blockchain/2018/06/28/Bitcoin-lightning-network.html">&lt;p&gt;Why another post about the lightning network (LN) of Bitcoin?&lt;/p&gt;

&lt;p&gt;The primary reason is that
some of the resources online are &lt;em&gt;not&lt;/em&gt; up to date.
The technological details of LN are not intuitive enough
and not easy to grasp.
Without examples, confusion and misunderstanding may arise.&lt;/p&gt;

&lt;p&gt;If you are a technician, researcher, engineer,
blockchain hobbyist or enthusiast
who already has some knowledge about LN,
this article is for you.
Do not worry if you know nothing about LN,
because this article leads you to the most useful resources
and tell you which piece of information is accurate in them.
Some understanding about
&lt;a href=&quot;https://github.com/bitcoin/bips/blob/master/bip-0141.mediawiki&quot;&gt;segregated witness&lt;/a&gt;
is strongly recommended before
reading the remaining part of this post,
as current LN payments heavily rely on it.&lt;/p&gt;

&lt;p&gt;In summary this post focuses on:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;what are the reliable resources to read/watch in order to understand LN;&lt;/li&gt;
  &lt;li&gt;what info inside these articles and videos is accurate and what is outdated;&lt;/li&gt;
  &lt;li&gt;how LN works, roughly;&lt;/li&gt;
  &lt;li&gt;how to find LN transactions on-chain.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Unfortunately, this article does &lt;em&gt;not&lt;/em&gt; discuss
how lightning network will affect bitcoin ecosystem,
its advantages and drawbacks,
how much transaction rate will improve, or even coin price!&lt;/p&gt;

&lt;p&gt;Good news: this article provides &lt;strong&gt;concrete examples&lt;/strong&gt; of payments via LN
that have been permanently written on Bitcoin blockchain!
So far I have not seen any other articles that give out examples.&lt;/p&gt;

&lt;p&gt;Last but not the least,
this post is my personal humble understanding on LN.
I am open for comments and critics.&lt;/p&gt;

&lt;h3 id=&quot;articles-and-videos&quot;&gt;Articles and videos&lt;/h3&gt;

&lt;p&gt;The GitHub repo
&lt;a href=&quot;https://github.com/bcongdon/awesome-lightning-network&quot;&gt;awesome-lightning-network&lt;/a&gt;
lists out many resources for LN.
It is a good starting point.
However in my point of view,
there is only one that is sufficiently comprehensive: the
&lt;a href=&quot;https://lightning.network/lightning-network-paper.pdf&quot;&gt;lightning network paper&lt;/a&gt;.
I strongly recommend you to read through it.&lt;/p&gt;

&lt;p&gt;You may have come across
&lt;a href=&quot;https://www.youtube.com/watch?v=8zVzw912wPo&amp;amp;t=2317s&quot;&gt;this YouTube video&lt;/a&gt;
on LN.
It appears as the 2&lt;sup&gt;nd&lt;/sup&gt; search result of
“lightning network” on YouTube.
Its weakness is that for bi-directional payments,
how to penalise an old commitment transaction and
revoke all the funds is not clear.
To understand the details of penalty
which is an essential part to ensure the safety and trustworthiness of LN,
please read the LN paper.
Penalty on HTLC transactions follows a very similar mechanism.
Later you will see both successfully claimed and penalised fund on-chain.&lt;/p&gt;

&lt;p&gt;Besides, the articles and videos share another fatal issue:
the scripts illustrated in them &lt;em&gt;cannot&lt;/em&gt; be found on the most recent blocks.
For example, I am &lt;em&gt;unable&lt;/em&gt; to find an input script
that follow the format below which is on page 31 of the LN paper
and implemented in a JavaScript LN protocol,
&lt;a href=&quot;https://github.com/yoursnetwork/yours-channels&quot;&gt;yours-channels&lt;/a&gt;.
However if you do find one, please leave your comment.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;OP IF
  OP HASH160 &amp;lt;Hash160 (R)&amp;gt; OP EQUALVERIFY
  2 &amp;lt;Ali c e 2&amp;gt; &amp;lt;Bob2&amp;gt; OP CHECKMULTISIG
OP ELSE
  2 &amp;lt;Ali c e 1&amp;gt; &amp;lt;Bob1&amp;gt; OP CHECKMULTISIG
OP ENDIF
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I suppose it is because
the specifications of LN have been updated and redefined in
&lt;a href=&quot;https://github.com/lightningnetwork/lightning-rfc&quot;&gt;this repo&lt;/a&gt;
called Basis of Lightning Technology (BOLT).
To be more specific, transactions and scripts are documented in
&lt;a href=&quot;https://github.com/lightningnetwork/lightning-rfc/blob/master/03-transactions.md&quot;&gt;BOLT #3&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;source-code&quot;&gt;Source code&lt;/h3&gt;

&lt;p&gt;There is a handful of implementations for LN.
The most popular two are the
&lt;a href=&quot;https://github.com/lightningnetwork/lnd&quot;&gt;LND&lt;/a&gt; written in Go
and
&lt;a href=&quot;https://github.com/ElementsProject/lightning&quot;&gt;lightning&lt;/a&gt; in C.
I have found these two repos after encountering the
&lt;a href=&quot;https://lnmainnet.gaben.win/&quot;&gt;mainnet LN explorer&lt;/a&gt;
which gets readings from them.&lt;/p&gt;

&lt;p&gt;Both of them strictly follow the
&lt;a href=&quot;https://github.com/lightningnetwork/lightning-rfc/blob/master/03-transactions.md&quot;&gt;BOLT #3&lt;/a&gt;
to build transactions and scripts.
Read more detailed source code here:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/lightningnetwork/lnd/blob/master/lnwallet/script_utils.go&quot;&gt;script_utils.go&lt;/a&gt;
in LND&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ElementsProject/lightning/blob/master/bitcoin/script.c&quot;&gt;script.c&lt;/a&gt; in lightning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As you will see soon,
BOLT #3 is the dominantly (probably the only) observable form on-chain.&lt;/p&gt;

&lt;h3 id=&quot;how-to-find-a-ln-transaction&quot;&gt;How to find a LN transaction&lt;/h3&gt;

&lt;p&gt;There are two major forms of transactions that are surely from LN:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2-of-2-MULTISIG embedded in P2WSH followed by
a conditional time locked input (for bi-directional channels)&lt;/li&gt;
  &lt;li&gt;2-of-2-MULTISIG embedded in P2WSH followed by at least one HTLC input&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first one is the dominant type of input script in LN and
takes up more than 80% of transaction inputs broadcast by LN.
Later you will see that the second form has two versions,
one for sender and the other for receiver.&lt;/p&gt;

&lt;h3 id=&quot;examples&quot;&gt;Examples&lt;/h3&gt;

&lt;p&gt;Here are some example hashes of LN transactions.&lt;/p&gt;

&lt;h5 id=&quot;to_local&quot;&gt;to_local&lt;/h5&gt;

&lt;p&gt;It is used to close a bi-directional channel and is
the most commonly seen form, as mentioned before.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;succeeded:
&lt;a href=&quot;https://btc.com/0191535bfda21f5dfec1c904775c5e2fbee8a985815c88d77258a0b42dba3526#in_0&quot;&gt;0191535bfda21f5dfec1c904775c5e2fbee8a985815c88d77258a0b42dba3526&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;penalised:
&lt;a href=&quot;https://btc.com/0da5e5dba5e793d50820c2275dab74912b121c8b7e34ce32a9dbfd4567a9bf8e#in_0&quot;&gt;0da5e5dba5e793d50820c2275dab74912b121c8b7e34ce32a9dbfd4567a9bf8e&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let us examine the successful case:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Its upstream input is a 2-of-2 MULTISIG embedded in P2WSH,
the funding transaction.&lt;/li&gt;
  &lt;li&gt;The funding transaction has two outputs (commitment transactions)
and the other is a P2WPKH.
The P2WPKH is not time locked and
has been sent to the counterparty of the channel.&lt;/li&gt;
  &lt;li&gt;Its input witness starts with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;sig&amp;gt; 0&lt;/code&gt; form
therefore its fund has already been successfully taken.
According to the LN paper, the LN channel is &lt;em&gt;fully closed&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Why the second input has been penalised?
Because there is a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt; right after the signature and
it executes the if-branch which revokes all the funds in the channel.
Both inputs were from the two outputs of
the previous funding transaction and there is only one output.
Therefore we can conclude that it is in a penalty transaction.&lt;/p&gt;

&lt;h5 id=&quot;sender-script&quot;&gt;sender script&lt;/h5&gt;

&lt;p&gt;Here are two examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;timeout:
&lt;a href=&quot;https://btc.com/a16f6d78a58d31fe7459887adf5bd6b4dd95277ea375d250c700cde9fa908bdb&quot;&gt;a16f6d78a58d31fe7459887adf5bd6b4dd95277ea375d250c700cde9fa908bdb&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;claimed by preimage:
&lt;a href=&quot;https://btc.com/89c744f0806a57a9b4634c320703cc941aaf272f290296373b709499064335e5&quot;&gt;89c744f0806a57a9b4634c320703cc941aaf272f290296373b709499064335e5&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The expenditures by timeout are easy to identify, as its format is simply
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0 &amp;lt;sig&amp;gt; &amp;lt;sig&amp;gt; 0&lt;/code&gt;.
How to identify if a HTLC transaction has used the preimage?
Here I would like to recommend the
&lt;a href=&quot;https://github.com/petertodd/python-bitcoinlib&quot;&gt;python bitcoin library&lt;/a&gt;.
I like it a lot because python provides power interactive terminal
and it is convenient to analyse bitcoin blockchain.&lt;/p&gt;

&lt;p&gt;Let us see the transaction input whose hash starts with “89c744”.
Its witness is in the form of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sig [unknown] scriptPubKey&lt;/code&gt;.
Later we will find out that the unknown part is
actually the hash160 of a secret, the hash that locks the contract.
A revocation script will appear in the exactly same form
but we shall see that the script does not execute the revocation path.&lt;/p&gt;

&lt;p&gt;The scriptPubKey part, according to BOLT #3, is decoded as&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bitcoin.core&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CScript&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CScript&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bytearray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromhex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'76a9149d908ebcc9e1913b808eb7b4ba47bc4d1b35ebd38763ac672102aa52226cbb5aaef23f175575c06feb16aa303e76f288be28c4760ef768c865977c820120876475527c210362c9ec1c0c7bb399037469b376e9e19d6aa0fbb58df811786b7425dea94b519a52ae67a9146e3bef3f86aed6d6f825f13d1fa070039c866c5c88ac6868'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CScript&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OP_DUP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_HASH160&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'9d908ebcc9e1913b808eb7b4ba47bc4d1b35ebd3'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_EQUAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_IF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_CHECKSIG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_ELSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'02aa52226cbb5aaef23f175575c06feb16aa303e76f288be28c4760ef768c86597'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_SWAP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'20'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_EQUAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_NOTIF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_DROP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_SWAP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'0362c9ec1c0c7bb399037469b376e9e19d6aa0fbb58df811786b7425dea94b519a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_CHECKMULTISIG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_ELSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_HASH160&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'6e3bef3f86aed6d6f825f13d1fa070039c866c5c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_EQUALVERIFY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_CHECKSIG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_ENDIF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OP_ENDIF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, let us see the hash value of the unknown part,&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bitcoin&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CScript&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bitcoin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;core&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Hash160&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bytearray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromhex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ae626cc4d6c208bdb3179b9d3efc7ae61779a9924b3852f01d0024afa84a4bbb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CScript&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'6e3bef3f86aed6d6f825f13d1fa070039c866c5c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;See? The hash160 of the previously unknown field is
equal to the value right after the last &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OP_HASH160&lt;/code&gt;
and before the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OP_EQUALVERIFY&lt;/code&gt;.
Therefore the fund is indeed taken by providing the preimage,
according to the HTLC script for senders defined in BOLT #3,
instead of being revoked.&lt;/p&gt;

&lt;p&gt;Here I am not going to show how the script should be executed
step by step on a stack.
You may do this yourself and keep in mind that
the exection path in a if-else branch is determined by a digit
whose value is either 1 or 0.&lt;/p&gt;

&lt;h5 id=&quot;receiver-script&quot;&gt;receiver script&lt;/h5&gt;

&lt;p&gt;Similarly, here are another two examples for receiver script:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;claimed by preimage:
&lt;a href=&quot;https://btc.com/36b1aff2ad0076be95b1ee1dc4036374998760c80c6583a6478a699e86658ac0&quot;&gt;36b1aff2ad0076be95b1ee1dc4036374998760c80c6583a6478a699e86658ac0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;timeout:
&lt;a href=&quot;https://btc.com/f9af9b93d66c7e5ee7dcbe0b53faa3d17aa6b9f4cc5b19f0985917b57d82c59a#in_0&quot;&gt;f9af9b93d66c7e5ee7dcbe0b53faa3d17aa6b9f4cc5b19f0985917b57d82c59a&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Again, if you find HTLC inputs that are penalised,
be sure to leave a comment.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;With all the resources presented by this article
and on-chain examples,
I hope you can better understand transactions in LN.&lt;/p&gt;

&lt;p&gt;Long live blockchain.&lt;/p&gt;</content><author><name>Wan Wenli</name></author><category term="blockchain" /><category term="bitcoin" /><summary type="html">Why another post about the lightning network (LN) of Bitcoin? The primary reason is that some of the resources online are not up to date. The technological details of LN are not intuitive enough and not easy to grasp. Without examples, confusion and misunderstanding may arise. If you are a technician, researcher, engineer, blockchain hobbyist or enthusiast who already has some knowledge about LN, this article is for you. Do not worry if you know nothing about LN, because this article leads you to the most useful resources and tell you which piece of information is accurate in them. Some understanding about segregated witness is strongly recommended before reading the remaining part of this post, as current LN payments heavily rely on it. In summary this post focuses on: what are the reliable resources to read/watch in order to understand LN; what info inside these articles and videos is accurate and what is outdated; how LN works, roughly; how to find LN transactions on-chain. Unfortunately, this article does not discuss how lightning network will affect bitcoin ecosystem, its advantages and drawbacks, how much transaction rate will improve, or even coin price! Good news: this article provides concrete examples of payments via LN that have been permanently written on Bitcoin blockchain! So far I have not seen any other articles that give out examples. Last but not the least, this post is my personal humble understanding on LN. I am open for comments and critics. Articles and videos The GitHub repo awesome-lightning-network lists out many resources for LN. It is a good starting point. However in my point of view, there is only one that is sufficiently comprehensive: the lightning network paper. I strongly recommend you to read through it. You may have come across this YouTube video on LN. It appears as the 2nd search result of “lightning network” on YouTube. Its weakness is that for bi-directional payments, how to penalise an old commitment transaction and revoke all the funds is not clear. To understand the details of penalty which is an essential part to ensure the safety and trustworthiness of LN, please read the LN paper. Penalty on HTLC transactions follows a very similar mechanism. Later you will see both successfully claimed and penalised fund on-chain. Besides, the articles and videos share another fatal issue: the scripts illustrated in them cannot be found on the most recent blocks. For example, I am unable to find an input script that follow the format below which is on page 31 of the LN paper and implemented in a JavaScript LN protocol, yours-channels. However if you do find one, please leave your comment. OP IF OP HASH160 &amp;lt;Hash160 (R)&amp;gt; OP EQUALVERIFY 2 &amp;lt;Ali c e 2&amp;gt; &amp;lt;Bob2&amp;gt; OP CHECKMULTISIG OP ELSE 2 &amp;lt;Ali c e 1&amp;gt; &amp;lt;Bob1&amp;gt; OP CHECKMULTISIG OP ENDIF I suppose it is because the specifications of LN have been updated and redefined in this repo called Basis of Lightning Technology (BOLT). To be more specific, transactions and scripts are documented in BOLT #3. Source code There is a handful of implementations for LN. The most popular two are the LND written in Go and lightning in C. I have found these two repos after encountering the mainnet LN explorer which gets readings from them. Both of them strictly follow the BOLT #3 to build transactions and scripts. Read more detailed source code here: script_utils.go in LND script.c in lightning As you will see soon, BOLT #3 is the dominantly (probably the only) observable form on-chain. How to find a LN transaction There are two major forms of transactions that are surely from LN: 2-of-2-MULTISIG embedded in P2WSH followed by a conditional time locked input (for bi-directional channels) 2-of-2-MULTISIG embedded in P2WSH followed by at least one HTLC input The first one is the dominant type of input script in LN and takes up more than 80% of transaction inputs broadcast by LN. Later you will see that the second form has two versions, one for sender and the other for receiver. Examples Here are some example hashes of LN transactions. to_local It is used to close a bi-directional channel and is the most commonly seen form, as mentioned before. succeeded: 0191535bfda21f5dfec1c904775c5e2fbee8a985815c88d77258a0b42dba3526 penalised: 0da5e5dba5e793d50820c2275dab74912b121c8b7e34ce32a9dbfd4567a9bf8e Let us examine the successful case: Its upstream input is a 2-of-2 MULTISIG embedded in P2WSH, the funding transaction. The funding transaction has two outputs (commitment transactions) and the other is a P2WPKH. The P2WPKH is not time locked and has been sent to the counterparty of the channel. Its input witness starts with &amp;lt;sig&amp;gt; 0 form therefore its fund has already been successfully taken. According to the LN paper, the LN channel is fully closed. Why the second input has been penalised? Because there is a 1 right after the signature and it executes the if-branch which revokes all the funds in the channel. Both inputs were from the two outputs of the previous funding transaction and there is only one output. Therefore we can conclude that it is in a penalty transaction. sender script Here are two examples: timeout: a16f6d78a58d31fe7459887adf5bd6b4dd95277ea375d250c700cde9fa908bdb claimed by preimage: 89c744f0806a57a9b4634c320703cc941aaf272f290296373b709499064335e5 The expenditures by timeout are easy to identify, as its format is simply 0 &amp;lt;sig&amp;gt; &amp;lt;sig&amp;gt; 0. How to identify if a HTLC transaction has used the preimage? Here I would like to recommend the python bitcoin library. I like it a lot because python provides power interactive terminal and it is convenient to analyse bitcoin blockchain. Let us see the transaction input whose hash starts with “89c744”. Its witness is in the form of sig [unknown] scriptPubKey. Later we will find out that the unknown part is actually the hash160 of a secret, the hash that locks the contract. A revocation script will appear in the exactly same form but we shall see that the script does not execute the revocation path. The scriptPubKey part, according to BOLT #3, is decoded as In [1]: from bitcoin.core import CScript In [2]: CScript(bytearray.fromhex('76a9149d908ebcc9e1913b808eb7b4ba47bc4d1b35ebd38763ac672102aa52226cbb5aaef23f175575c06feb16aa303e76f288be28c4760ef768c865977c820120876475527c210362c9ec1c0c7bb399037469b376e9e19d6aa0fbb58df811786b7425dea94b519a52ae67a9146e3bef3f86aed6d6f825f13d1fa070039c866c5c88ac6868')) Out[2]: CScript([OP_DUP, OP_HASH160, x('9d908ebcc9e1913b808eb7b4ba47bc4d1b35ebd3'), OP_EQUAL, OP_IF, OP_CHECKSIG, OP_ELSE, x('02aa52226cbb5aaef23f175575c06feb16aa303e76f288be28c4760ef768c86597'), OP_SWAP, OP_SIZE, x('20'), OP_EQUAL, OP_NOTIF, OP_DROP, 2, OP_SWAP, x('0362c9ec1c0c7bb399037469b376e9e19d6aa0fbb58df811786b7425dea94b519a'), 2, OP_CHECKMULTISIG, OP_ELSE, OP_HASH160, x('6e3bef3f86aed6d6f825f13d1fa070039c866c5c'), OP_EQUALVERIFY, OP_CHECKSIG, OP_ENDIF, OP_ENDIF]) Next, let us see the hash value of the unknown part, In [1]: import bitcoin In [2]: CScript([bitcoin.core.Hash160(bytearray.fromhex('ae626cc4d6c208bdb3179b9d3efc7ae61779a9924b3852f01d0024afa84a4bbb'))]) Out[2]: CScript([x('6e3bef3f86aed6d6f825f13d1fa070039c866c5c')]) See? The hash160 of the previously unknown field is equal to the value right after the last OP_HASH160 and before the OP_EQUALVERIFY. Therefore the fund is indeed taken by providing the preimage, according to the HTLC script for senders defined in BOLT #3, instead of being revoked. Here I am not going to show how the script should be executed step by step on a stack. You may do this yourself and keep in mind that the exection path in a if-else branch is determined by a digit whose value is either 1 or 0. receiver script Similarly, here are another two examples for receiver script: claimed by preimage: 36b1aff2ad0076be95b1ee1dc4036374998760c80c6583a6478a699e86658ac0 timeout: f9af9b93d66c7e5ee7dcbe0b53faa3d17aa6b9f4cc5b19f0985917b57d82c59a Again, if you find HTLC inputs that are penalised, be sure to leave a comment. Summary With all the resources presented by this article and on-chain examples, I hope you can better understand transactions in LN. Long live blockchain.</summary></entry><entry><title type="html">Apache Spark’s number of cores rethought</title><link href="https://wanwenli.com/spark/2018/04/02/spark-executor-cores.html" rel="alternate" type="text/html" title="Apache Spark's number of cores rethought" /><published>2018-04-02T00:00:00+08:00</published><updated>2018-04-02T00:00:00+08:00</updated><id>https://wanwenli.com/spark/2018/04/02/spark-executor-cores</id><content type="html" xml:base="https://wanwenli.com/spark/2018/04/02/spark-executor-cores.html">&lt;p&gt;There are tons of articles talking about setting the number of executors and cores for &lt;a href=&quot;http://spark.apache.org/&quot;&gt;Spark&lt;/a&gt; applications.
Hence I am &lt;em&gt;not&lt;/em&gt; going to discuss anything about tuning these 2 parameters.
Instead I would like to address what does the values of these parameters mean
for nodes or containers which are executing your tasks.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;The number of cores has no direct relation to physical CPU cores,
instead it is a logical counter
which determines the number of concurrent
tasks that are able to run on one executor.
I believe that many articles you can find have already addressed it.
However from the perspective of servers or containers
that receive tasks from the driver process,
the number of cores is able to limit the total number of tasks running
on one server/node/container.&lt;/p&gt;

&lt;h3 id=&quot;standalone-mode&quot;&gt;Standalone mode&lt;/h3&gt;

&lt;p&gt;Standalone mode is very easy to setup but has few features in
scheduling and access control.
Though I have touched both standalone and YARN mode,
starting from standalone mode is a good choice
because the implementation details are easy to inspect, compared to YARN mode
where lots of details are handled by YARN.&lt;/p&gt;

&lt;p&gt;Let’s start from worker process first.
It is recommended that each server only runs one single worker process
and I am going to treat it as an assumption.&lt;/p&gt;

&lt;p&gt;What are workers and executors?&lt;/p&gt;

&lt;p&gt;Each worker is Java process and so is an executor.
If the number of cores is not specified when starting a worker,
the worker will pick the number of physical cores from OS
to be its capacity of cores.
For Spark applications that demand executors,
worker processes spawn executor processes as responses to such requests.
Upon each creation of an executor process,
worker deduct the amount of memory and cores from the total value
it controls.
In &lt;a href=&quot;&quot;&gt;Worker&lt;/a&gt;
class, you can find in method &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;launchExecutor&lt;/code&gt; that
for each launch of a new executor, the count of used cores is incremented.
Therefore as I said,
the number of memory and cores are more like
&lt;em&gt;logical&lt;/em&gt; values rather than the actual amount of resources each executor uses.&lt;/p&gt;

&lt;p&gt;What does it look like in deeper details?
The number of memory (controlled by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.executor.memory&lt;/code&gt;)
determines the &lt;strong&gt;maximum heap size&lt;/strong&gt; of executor process,
by forming the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-Xmx&lt;/code&gt; parameter.
For example if you pass in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--conf spark.executor.memory=10240m&lt;/code&gt;
when submitting an Spark application,
the executor Java process will include a command line argument as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-Xmx 10240m&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/worker/ExecutorRunner.scala&quot;&gt;ExecutorRunner&lt;/a&gt;
is the wrapper class around each executor process.
It has an attribute which is an instance of Java
&lt;a href=&quot;https://docs.oracle.com/javase/8/docs/api/java/lang/Process.html&quot;&gt;Process&lt;/a&gt;.
Actually &lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/worker/Worker.scala&quot;&gt;CoarseGrainedExecutorBackend&lt;/a&gt;
is the main entry point class of executor process
which is able to be observed by using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -ef&lt;/code&gt; command.
As you dig deeper in the source code,
you should be able to find that each task is a thread submitted
to a thread pool.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.executor.cores&lt;/code&gt; thus controls the upper limit of concurrent tasks
running in one executor process.
Their resources are shared within one process.
As quite a number of online sources have pointed out,
a big number of cores, say 8,
causes the overhead of context switch to be big and
actually slow down the overall performance.
A number between 2 and 4 (inclusive) is recommended for most Spark applications.&lt;/p&gt;

&lt;h3 id=&quot;yarn-mode&quot;&gt;YARN mode&lt;/h3&gt;

&lt;p&gt;YARN provides a much richer set of features such as
(very fine-grained) capacity scheduling, label-based scheduling and access control.&lt;/p&gt;

&lt;p&gt;The table below helps you compare and understand standalone and YARN mode
side by side.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;YARN&lt;/th&gt;
      &lt;th&gt;standalone&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;ResourceManager&lt;/td&gt;
      &lt;td&gt;Master&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;NodeManager&lt;/td&gt;
      &lt;td&gt;Worker&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.nodemanager.resource.memory-mb&lt;/td&gt;
      &lt;td&gt;–memory&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.nodemanager.resource.cpu-vcores&lt;/td&gt;
      &lt;td&gt;–cores&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;A major difference between YARN and standalone mode in terms of resource control
is that workers stop spawning new executors
when either of the resources is exhausted.
However the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DefaultResourceCalculator&lt;/code&gt; only uses &lt;em&gt;memory&lt;/em&gt; to control
the resources used by executors.
As a result sometimes you can see that the available of vcores on a node
become negative.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DominantResourceCalculator&lt;/code&gt; behaves the same way as workers in standalone mode.
It chooses the dominant resource as the upper limit for resource usage.&lt;/p&gt;

&lt;h3 id=&quot;an-infra-perspective&quot;&gt;An infra perspective&lt;/h3&gt;

&lt;p&gt;I have heard that some companies use Kubernetes to spawn containers to host NodeManagers,
when there are huge demands for resources.&lt;/p&gt;

&lt;p&gt;An ideal scenario is where the memory and cores in your cluster
are consumed at the same pace.
When memory is used up,
cores should be exhausted as well.
To achieve better utility of your Hadoop slaves,
tune these parameters such that
when memory and cores are used up by executors,
memory in OS is close to fully utilized and CPU load is slightly below
maximum capacity.
This advice is given in condition that Spark executors are the dominant
processes running on your servers
and you should always leave some memory and computational power for
other processes than Spark executors and tasks.
Your Spark applications might have very strange behavior,
sometimes even failures,
when the CPU load of Hadoop slaves is extremely high.&lt;/p&gt;

&lt;p&gt;If you have both IO intensive (such as ETL)
and computationally intensive applications (such as data science apps),
consider introducing label-based scheduling before tuning.&lt;/p&gt;

&lt;h3 id=&quot;epilogue-data-engineering-in-shopee&quot;&gt;Epilogue: data engineering in Shopee&lt;/h3&gt;

&lt;p&gt;As the primary data provider in a leading E-commerce platform operating across Southeast Asia,
data engineering team is able to handle TB-level in one ETL flow and
this number is still increasing fast.
We run Spark jobs on top of an in-house Hadoop cluster
whose size is among the top-tier in Singapore as well as SEA region, hopefully.&lt;/p&gt;</content><author><name>Wan Wenli</name></author><category term="spark" /><summary type="html">There are tons of articles talking about setting the number of executors and cores for Spark applications. Hence I am not going to discuss anything about tuning these 2 parameters. Instead I would like to address what does the values of these parameters mean for nodes or containers which are executing your tasks. Summary The number of cores has no direct relation to physical CPU cores, instead it is a logical counter which determines the number of concurrent tasks that are able to run on one executor. I believe that many articles you can find have already addressed it. However from the perspective of servers or containers that receive tasks from the driver process, the number of cores is able to limit the total number of tasks running on one server/node/container. Standalone mode Standalone mode is very easy to setup but has few features in scheduling and access control. Though I have touched both standalone and YARN mode, starting from standalone mode is a good choice because the implementation details are easy to inspect, compared to YARN mode where lots of details are handled by YARN. Let’s start from worker process first. It is recommended that each server only runs one single worker process and I am going to treat it as an assumption. What are workers and executors? Each worker is Java process and so is an executor. If the number of cores is not specified when starting a worker, the worker will pick the number of physical cores from OS to be its capacity of cores. For Spark applications that demand executors, worker processes spawn executor processes as responses to such requests. Upon each creation of an executor process, worker deduct the amount of memory and cores from the total value it controls. In Worker class, you can find in method launchExecutor that for each launch of a new executor, the count of used cores is incremented. Therefore as I said, the number of memory and cores are more like logical values rather than the actual amount of resources each executor uses. What does it look like in deeper details? The number of memory (controlled by spark.executor.memory) determines the maximum heap size of executor process, by forming the -Xmx parameter. For example if you pass in --conf spark.executor.memory=10240m when submitting an Spark application, the executor Java process will include a command line argument as -Xmx 10240m. ExecutorRunner is the wrapper class around each executor process. It has an attribute which is an instance of Java Process. Actually CoarseGrainedExecutorBackend is the main entry point class of executor process which is able to be observed by using ps -ef command. As you dig deeper in the source code, you should be able to find that each task is a thread submitted to a thread pool. spark.executor.cores thus controls the upper limit of concurrent tasks running in one executor process. Their resources are shared within one process. As quite a number of online sources have pointed out, a big number of cores, say 8, causes the overhead of context switch to be big and actually slow down the overall performance. A number between 2 and 4 (inclusive) is recommended for most Spark applications. YARN mode YARN provides a much richer set of features such as (very fine-grained) capacity scheduling, label-based scheduling and access control. The table below helps you compare and understand standalone and YARN mode side by side. YARN standalone ResourceManager Master NodeManager Worker yarn.nodemanager.resource.memory-mb –memory yarn.nodemanager.resource.cpu-vcores –cores A major difference between YARN and standalone mode in terms of resource control is that workers stop spawning new executors when either of the resources is exhausted. However the DefaultResourceCalculator only uses memory to control the resources used by executors. As a result sometimes you can see that the available of vcores on a node become negative. DominantResourceCalculator behaves the same way as workers in standalone mode. It chooses the dominant resource as the upper limit for resource usage. An infra perspective I have heard that some companies use Kubernetes to spawn containers to host NodeManagers, when there are huge demands for resources. An ideal scenario is where the memory and cores in your cluster are consumed at the same pace. When memory is used up, cores should be exhausted as well. To achieve better utility of your Hadoop slaves, tune these parameters such that when memory and cores are used up by executors, memory in OS is close to fully utilized and CPU load is slightly below maximum capacity. This advice is given in condition that Spark executors are the dominant processes running on your servers and you should always leave some memory and computational power for other processes than Spark executors and tasks. Your Spark applications might have very strange behavior, sometimes even failures, when the CPU load of Hadoop slaves is extremely high. If you have both IO intensive (such as ETL) and computationally intensive applications (such as data science apps), consider introducing label-based scheduling before tuning. Epilogue: data engineering in Shopee As the primary data provider in a leading E-commerce platform operating across Southeast Asia, data engineering team is able to handle TB-level in one ETL flow and this number is still increasing fast. We run Spark jobs on top of an in-house Hadoop cluster whose size is among the top-tier in Singapore as well as SEA region, hopefully.</summary></entry><entry><title type="html">Offset topic and consumer group coordinator of Kafka</title><link href="https://wanwenli.com/kafka/2016/11/04/Kafka-Group-Coordinator.html" rel="alternate" type="text/html" title="Offset topic and consumer group coordinator of Kafka" /><published>2016-11-04T00:00:00+08:00</published><updated>2016-11-04T00:00:00+08:00</updated><id>https://wanwenli.com/kafka/2016/11/04/Kafka-Group-Coordinator</id><content type="html" xml:base="https://wanwenli.com/kafka/2016/11/04/Kafka-Group-Coordinator.html">&lt;p&gt;This article is to discuss two subjects
that are not frequently or clearly covered by official document or
online sources.&lt;/p&gt;

&lt;h4 id=&quot;offset-topic-the-__consumer_offsets-topic&quot;&gt;Offset topic (the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__consumer_offsets&lt;/code&gt; topic)&lt;/h4&gt;

&lt;p&gt;It is the only mysterious topic in Kafka log
and it cannot be deleted by using
&lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/admin/TopicCommand.scala&quot;&gt;TopicCommand&lt;/a&gt;.
Unfortunately there is no dedicated official documentation
to explain this internal topic.
The closest source I can find is
&lt;a href=&quot;http://www.slideshare.net/jjkoshy/offset-management-in-kafka&quot;&gt;this set of slides&lt;/a&gt;.
I strongly recommend reading it if you wish to understand
how this internal topic works.&lt;/p&gt;

&lt;p&gt;In short,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__consumer_offsets&lt;/code&gt; is used to store &lt;em&gt;offsets&lt;/em&gt; of consumers
which was previously stored only in ZooKeeper before version 0.8.1.1.
At the latest version of 0.8.X serious, i.e. 0.8.2.2,
the storage location of offsets can be configured by
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;offsets.storage&lt;/code&gt; whose value can be either &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kafka&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;zookeeper&lt;/code&gt;.
If it is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kafka&lt;/code&gt;,
consumers are still able to commit offsets to ZooKeeper
by enabling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dual.commit.enabled&lt;/code&gt;.
However since version 0.9,
consumer offsets have been designed to be stored on brokers only.&lt;/p&gt;

&lt;p&gt;The partition key of the messages in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__consumer_offsets&lt;/code&gt;
was handled in
&lt;a href=&quot;https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/server/OffsetManager.scala&quot;&gt;OffsetManager&lt;/a&gt;
at version 0.8.X
and has been named as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OffsetKey&lt;/code&gt; in
&lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/coordinator/GroupMetadataManager.scala&quot;&gt;GroupMetadataManager&lt;/a&gt;
since version 0.9.0.
It contains three pieces of information: groupId, topic and partition number,
and the key is serialized/de-serialized according to a schema called
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OFFSET_COMMIT_KEY_SCHEMA&lt;/code&gt;.
The usage of schema is primarily for backward compatibility.
Unlike the behavior of
&lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/DefaultPartitioner.java&quot;&gt;DefaultPartitioner&lt;/a&gt;,
the partition number inside &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__consumer_offsets&lt;/code&gt; is &lt;em&gt;not&lt;/em&gt;
determined by the hash value of partition key
but only determined by the hash value of consumer group,
which is as simple as&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Utils.abs(groupId.hashCode) % numPartitions
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;numPartitions&lt;/code&gt; is configured by the value of
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;offsets.topic.num.partitions&lt;/code&gt; in broker configs
and is 50 by default.
This algorithm will be re-introduced later
in the part of consumer group coordination.&lt;/p&gt;

&lt;p&gt;The values of offset messages which is named
&lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/common/OffsetMetadataAndError.scala&quot;&gt;OffsetMetadata&lt;/a&gt;
have two versions.
At version 0.8.X, the value contains offset, metadata (often empty)
and a timestamp
while the timestamp had been split into commit and expire timestamps
since version 0.9.0.
Console consumers are able to consume messages from internal topics
and print them out nicely.
A sample command has been shown below:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./kafka-simple-consumer-shell.sh --topic __consumer_offsets \
--partition 49 \
--broker-list localhost:9092 \
--formatter &quot;kafka.server.OffsetManager\$OffsetsMessageFormatter&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;By the way, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;absolute(&quot;testGroup&quot;.hashCode() % 50) = 49&lt;/code&gt;
which is the reason why partition 49 was specified.
It prints out:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[testGroup,testTopic-development,0]::OffsetAndMetadata[11,NO_METADATA,1478243992053]
[testGroup,testTopic-development,0]::OffsetAndMetadata[12,NO_METADATA,1478243992086]
[testGroup,testTopic-development,0]::OffsetAndMetadata[13,NO_METADATA,1478243992096]
[testGroup,testTopic-development,0]::OffsetAndMetadata[14,NO_METADATA,1478243992110]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However this is not the end of story,
because &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__consumer_offsets&lt;/code&gt; is also used by group coordinator
to store group metadata!
The following section discusses another new feature
introduced since version 0.9.0.&lt;/p&gt;

&lt;h4 id=&quot;group-coordinator-coordinated-rebalance&quot;&gt;Group coordinator (coordinated rebalance)&lt;/h4&gt;

&lt;p&gt;This section is my humble and shallow understanding about
broker coordinator of consumer groups.
Correct me if I ever miss something or make any mistake.&lt;/p&gt;

&lt;p&gt;The introduction of coordinator, according to the
&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Detailed+Consumer+Coordinator+Design&quot;&gt;official wiki of Kafka&lt;/a&gt;,
is to solve the &lt;em&gt;split brain&lt;/em&gt; problem
which is a well known problem in a distributed system.&lt;/p&gt;</content><author><name>Wan Wenli</name></author><category term="kafka" /><category term="consumer-group" /><summary type="html">This article is to discuss two subjects that are not frequently or clearly covered by official document or online sources. Offset topic (the __consumer_offsets topic) It is the only mysterious topic in Kafka log and it cannot be deleted by using TopicCommand. Unfortunately there is no dedicated official documentation to explain this internal topic. The closest source I can find is this set of slides. I strongly recommend reading it if you wish to understand how this internal topic works. In short, __consumer_offsets is used to store offsets of consumers which was previously stored only in ZooKeeper before version 0.8.1.1. At the latest version of 0.8.X serious, i.e. 0.8.2.2, the storage location of offsets can be configured by offsets.storage whose value can be either kafka or zookeeper. If it is kafka, consumers are still able to commit offsets to ZooKeeper by enabling dual.commit.enabled. However since version 0.9, consumer offsets have been designed to be stored on brokers only. The partition key of the messages in __consumer_offsets was handled in OffsetManager at version 0.8.X and has been named as OffsetKey in GroupMetadataManager since version 0.9.0. It contains three pieces of information: groupId, topic and partition number, and the key is serialized/de-serialized according to a schema called OFFSET_COMMIT_KEY_SCHEMA. The usage of schema is primarily for backward compatibility. Unlike the behavior of DefaultPartitioner, the partition number inside __consumer_offsets is not determined by the hash value of partition key but only determined by the hash value of consumer group, which is as simple as Utils.abs(groupId.hashCode) % numPartitions Here the numPartitions is configured by the value of offsets.topic.num.partitions in broker configs and is 50 by default. This algorithm will be re-introduced later in the part of consumer group coordination. The values of offset messages which is named OffsetMetadata have two versions. At version 0.8.X, the value contains offset, metadata (often empty) and a timestamp while the timestamp had been split into commit and expire timestamps since version 0.9.0. Console consumers are able to consume messages from internal topics and print them out nicely. A sample command has been shown below: ./kafka-simple-consumer-shell.sh --topic __consumer_offsets \ --partition 49 \ --broker-list localhost:9092 \ --formatter &quot;kafka.server.OffsetManager\$OffsetsMessageFormatter&quot; By the way, absolute(&quot;testGroup&quot;.hashCode() % 50) = 49 which is the reason why partition 49 was specified. It prints out: [testGroup,testTopic-development,0]::OffsetAndMetadata[11,NO_METADATA,1478243992053] [testGroup,testTopic-development,0]::OffsetAndMetadata[12,NO_METADATA,1478243992086] [testGroup,testTopic-development,0]::OffsetAndMetadata[13,NO_METADATA,1478243992096] [testGroup,testTopic-development,0]::OffsetAndMetadata[14,NO_METADATA,1478243992110] However this is not the end of story, because __consumer_offsets is also used by group coordinator to store group metadata! The following section discusses another new feature introduced since version 0.9.0. Group coordinator (coordinated rebalance) This section is my humble and shallow understanding about broker coordinator of consumer groups. Correct me if I ever miss something or make any mistake. The introduction of coordinator, according to the official wiki of Kafka, is to solve the split brain problem which is a well known problem in a distributed system.</summary></entry></feed>